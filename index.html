<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neil Gautam | AI Researcher</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&family=JetBrains+Mono:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <!-- Animated Background -->
    <div class="neural-bg">
        <canvas id="neural-canvas"></canvas>
    </div>

    <!-- Top Navigation Bar -->
    <nav class="top-nav">
        <div class="nav-container">
            <div class="nav-brand">
                <span class="brand-text">neil_gautam@ai_researcher</span>
                <span class="terminal-cursor">‚ñà</span>
            </div>
            <div class="nav-items">
                <a href="#hero" class="nav-item active" data-section="hero">
                    <span class="nav-icon">‚óè</span>
                    <span class="nav-text">INIT</span>
                </a>
                <a href="#about" class="nav-item" data-section="about">
                    <span class="nav-icon">‚óÜ</span>
                    <span class="nav-text">PROFILE</span>
                </a>
                <a href="#research" class="nav-item" data-section="research">
                    <span class="nav-icon">‚ñ≤</span>
                    <span class="nav-text">RESEARCH</span>
                </a>
                <a href="#publications" class="nav-item" data-section="publications">
                    <span class="nav-icon">‚ñ†</span>
                    <span class="nav-text">PAPERS</span>
                </a>
                <a href="#experience" class="nav-item" data-section="experience">
                    <span class="nav-icon">‚óâ</span>
                    <span class="nav-text">EXPERIENCE</span>
                </a>
                <a href="#contact" class="nav-item" data-section="contact">
                    <span class="nav-icon">‚ú¶</span>
                    <span class="nav-text">CONNECT</span>
                </a>
            </div>
        </div>
    </nav>

    <!-- Enhanced Hero Section with Larger Terminal -->
    <section id="hero" class="section hero-section">
        <div class="hero-container">
            <div class="terminal-window-large">
                <div class="terminal-header">
                    <div class="terminal-controls">
                        <span class="control red"></span>
                        <span class="control yellow"></span>
                        <span class="control green"></span>
                    </div>
                    <div class="terminal-title">neil_gautam@ai_researcher:~$</div>
                </div>
                <div class="terminal-body">
                    <div class="terminal-main">
                        <div class="typing-text">
                            <span class="prompt">$</span> <span class="command">whoami</span>
                            <div class="output">
                                <div class="name-display">NEIL GAUTAM</div>
                                <div class="role-text">AI Researcher</div>
                                <div class="specialization">[ Embodied AI ‚Ä¢ Human-Centric Computer Vision ‚Ä¢ Egocentric Systems ]</div>
                            </div>
                        </div>
                        <div class="typing-text delay-1">
                            <span class="prompt">$</span> <span class="command">cat research_focus.txt</span>
                            <div class="output research-focus-long">
                                <p>My research interest lies at the intersection of embodied AI and human-centric computer vision, where I develop intelligent systems that can understand and predict how humans perceive, navigate, and interact with complex 3D environments. Drawing from my experience building production-scale vision systems and generative models, I've evolved toward addressing fundamental questions about human behavior prediction and spatial scene understanding.</p>
                                
                                <p>My current focus centers on egocentric vision and affordance modeling‚Äîdeveloping frameworks that move beyond traditional computer vision to predict how humans will interact with their environment over time, bridging 2D visual perception with 3D spatial reasoning through advanced generative architectures, particularly diffusion models applied across diverse domains from healthcare to robust vision systems.</p>
                                
                                <p>What drives my research is the conviction that truly intelligent AI must understand the intentionality behind human actions, not just recognize visual patterns. My interdisciplinary approach combines computer vision, generative AI, and biomedical applications, positioning me to tackle fundamental challenges in embodied AI where spatial-temporal understanding of human behavior is critical. Whether developing memory-based architectures for anomaly detection, real-time monitoring systems that construct 3D scene representations, or geometry-aware reconstruction models for medical imaging analysis, I'm consistently working toward AI systems that don't just process visual data, but comprehend the physics, intentionality, and temporal dynamics of how humans move through and interact with their world‚Äîcreating AI that truly understands human behavior in 3D space.</p>
                            </div>
                        </div>
                        <div class="typing-text delay-2">
                            <span class="prompt">$</span> <span class="command">echo $CONTACT</span>
                            <div class="output contact-links">
                                <a href="mailto:neilgautam.24@tamu.edu" class="contact-link">
                                    <span class="link-icon">@</span> neilgautam.24@tamu.edu
                                </a>
                                <a href="https://www.linkedin.com/in/neil-gautam-a928971a5/" target="_blank" class="contact-link">
                                    <span class="link-icon">IN</span> LinkedIn
                                </a>
                                <a href="https://github.com/neilgautam24-tamu" target="_blank" class="contact-link">
                                    <span class="link-icon">GH</span> GitHub
                                </a>
                                <a href="https://scholar.google.com/citations?user=CUISVw8AAAAJ&hl=en" target="_blank" class="contact-link">
                                    <span class="link-icon">GS</span> Scholar
                                </a>
                            </div>
                        </div>
                        <div class="cursor-line">
                            <span class="prompt">$</span> <span class="blinking-cursor">‚ñà</span>
                        </div>
                    </div>
                    
                    <!-- Integrated Performance Metrics -->
                    <div class="terminal-sidebar">
                        <div class="metrics-header">PERFORMANCE_METRICS</div>
                        <div class="metrics-grid">
                            <div class="metric-item">
                                <div class="metric-number">4.0</div>
                                <div class="metric-label">GPA</div>
                                <div class="metric-bar"><div class="metric-fill" style="width: 100%"></div></div>
                            </div>
                            <div class="metric-item">
                                <div class="metric-number">3</div>
                                <div class="metric-label">PUBLICATIONS</div>
                                <div class="metric-bar"><div class="metric-fill" style="width: 85%"></div></div>
                            </div>
                            <div class="metric-item">
                                <div class="metric-number">6+</div>
                                <div class="metric-label">RESEARCH PROJECTS</div>
                                <div class="metric-bar"><div class="metric-fill" style="width: 95%"></div></div>
                            </div>
                            <div class="metric-item">
                                <div class="metric-number">3</div>
                                <div class="metric-label">YEARS EXP</div>
                                <div class="metric-bar"><div class="metric-fill" style="width: 80%"></div></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Enhanced About Section with Advisors -->
    <section id="about" class="section about-section">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">NEURAL_PROFILE.exe</h2>
                <div class="section-subtitle">Pioneering Embodied AI & Human-Centric Vision</div>
            </div>
            
            <div class="profile-layout">
                <div class="profile-main">
                    <div class="text-block">
                        <div class="block-header">[CURRENT_STATUS]</div>
                        <p>MS Computer Science @ Texas A&M University (GPA: 4.0/4.0). Specializing in Embodied AI, Egocentric Vision, and Human-Centric Computer Vision under the guidance of leading researchers in computer vision and medical imaging.</p>
                    </div>
                    
                    <div class="text-block">
                        <div class="block-header">[RESEARCH_PHILOSOPHY]</div>
                        <p>I believe that truly intelligent AI must understand the intentionality behind human actions, not just recognize visual patterns. My interdisciplinary approach combines computer vision, generative AI, and biomedical applications, positioning me to tackle fundamental challenges in embodied AI where spatial-temporal understanding of human behavior is critical.</p>
                    </div>
                    
                    <div class="text-block">
                        <div class="block-header">[RESEARCH_VISION]</div>
                        <p>My goal is to develop AI systems that don't just process visual data, but comprehend the physics, intentionality, and temporal dynamics of how humans move through and interact with their world‚Äîcreating AI that truly understands human behavior in 3D space.</p>
                    </div>

                    <!-- Research Network -->
                    <div class="research-network">
                        <div class="network-section">
                            <div class="block-header">[RESEARCH_ADVISORS]</div>
                            <div class="advisor-grid">
                                <div class="advisor-card">
                                    <div class="advisor-icon">üß†</div>
                                    <div class="advisor-info">
                                        <h4><a href="https://czhang0528.github.io/" target="_blank">Prof. Cheng Zhang</a></h4>
                                        <p>Main Advisor - Egocentric Vision & 3D Scene Understanding</p>
                                    </div>
                                </div>
                                <div class="advisor-card">
                                    <div class="advisor-icon">ü´Ä</div>
                                    <div class="advisor-info">
                                        <h4><a href="https://engineering.tamu.edu/biomedical/profiles/avazmohammadi-reza.html" target="_blank">Dr. Reza Avazmohammadi</a></h4>
                                        <p>Co-Advisor - Medical Imaging & Cardiac Analysis</p>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <div class="network-section">
                            <div class="block-header">[INDUSTRY_MENTORS]</div>
                            <div class="mentor-grid">
                                <div class="mentor-card">
                                    <div class="mentor-icon">üîç</div>
                                    <div class="mentor-info">
                                        <h4><a href="https://www.linkedin.com/in/hariprasad-p-s-162b0778/" target="_blank">Hariprasad P S</a></h4>
                                        <p>HyperVerge Ltd - Deep Learning & Anomaly Detection</p>
                                    </div>
                                </div>
                                <div class="mentor-card">
                                    <div class="mentor-icon">üé®</div>
                                    <div class="mentor-info">
                                        <h4><a href="https://www.linkedin.com/in/nikhil-bartwal-b07b501a3/" target="_blank">Nikhil Bartwal</a></h4>
                                        <p>AfterShoot - AI-Powered Photo Enhancement</p>
                                    </div>
                                </div>
                                <div class="mentor-card">
                                    <div class="mentor-icon">üìà</div>
                                    <div class="mentor-info">
                                        <h4><a href="https://www.linkedin.com/in/suhruth-eedara-93858412b/" target="_blank">Suhruth Eedara</a></h4>
                                        <p>Savart - Financial NLP & LLM Applications</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                
                <div class="skills-matrix">
                    <div class="matrix-header">SKILL_MATRIX.exe</div>
                    <div class="skill-categories">
                        <div class="skill-category">
                            <div class="category-name">[RESEARCH_DOMAINS]</div>
                            <div class="skill-tags">
                                <span class="skill-tag">Embodied AI</span>
                                <span class="skill-tag">Egocentric Vision</span>
                                <span class="skill-tag">Human-Centric CV</span>
                                <span class="skill-tag">3D Scene Understanding</span>
                                <span class="skill-tag">Diffusion Models</span>
                                <span class="skill-tag">Medical Imaging</span>
                                <span class="skill-tag">3D Gaussian Splatting</span>
                                <span class="skill-tag">Multi-view Tracking</span>
                            </div>
                        </div>
                        
                        <div class="skill-category">
                            <div class="category-name">[ML_FRAMEWORKS]</div>
                            <div class="skill-progress">
                                <div class="progress-item">
                                    <span class="tech-name">PyTorch</span>
                                    <div class="progress-bar"><div class="progress-fill" data-width="98%"></div></div>
                                    <span class="progress-percent">98%</span>
                                </div>
                                <div class="progress-item">
                                    <span class="tech-name">TensorFlow</span>
                                    <div class="progress-bar"><div class="progress-fill" data-width="85%"></div></div>
                                    <span class="progress-percent">85%</span>
                                </div>
                                <div class="progress-item">
                                    <span class="tech-name">Hugging Face</span>
                                    <div class="progress-bar"><div class="progress-fill" data-width="92%"></div></div>
                                    <span class="progress-percent">92%</span>
                                </div>
                            </div>
                        </div>
                        
                        <div class="skill-category">
                            <div class="category-name">[PROGRAMMING]</div>
                            <div class="skill-progress">
                                <div class="progress-item">
                                    <span class="tech-name">Python</span>
                                    <div class="progress-bar"><div class="progress-fill" data-width="98%"></div></div>
                                    <span class="progress-percent">98%</span>
                                </div>
                                <div class="progress-item">
                                    <span class="tech-name">C++</span>
                                    <div class="progress-bar"><div class="progress-fill" data-width="82%"></div></div>
                                    <span class="progress-percent">82%</span>
                                </div>
                                <div class="progress-item">
                                    <span class="tech-name">Rust</span>
                                    <div class="progress-bar"><div class="progress-fill" data-width="75%"></div></div>
                                    <span class="progress-percent">75%</span>
                                </div>
                            </div>
                        </div>
                        
                        <div class="skill-category">
                            <div class="category-name">[SPECIALIZED_TOOLS]</div>
                            <div class="skill-tags">
                                <span class="skill-tag">YOLO</span>
                                <span class="skill-tag">ONNX</span>
                                <span class="skill-tag">Open3D</span>
                                <span class="skill-tag">Viser</span>
                                <span class="skill-tag">Rerun.io</span>
                                <span class="skill-tag">SMPL</span>
                                <span class="skill-tag">OpenCV</span>
                                <span class="skill-tag">Docker</span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Redesigned Research Timeline -->
    <section id="research" class="section research-section">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">RESEARCH_TIMELINE.exe</h2>
                <div class="section-subtitle">Neural Networks Meet Reality</div>
            </div>
            
            <div class="research-grid-layout">
                <div class="research-card featured current">
                    <div class="card-ribbon">ACTIVE</div>
                    <div class="research-header">
                        <div class="research-icon">ü§ñ</div>
                        <div class="research-meta">
                            <h3>Egocentric Fine-Grained Object Interaction Trajectory & Affordance Prediction</h3>
                            <div class="research-details">
                                <span class="research-date">May 2025 - Present</span>
                                <span class="research-advisor">Advisor: <a href="https://czhang0528.github.io/" target="_blank">Prof. Cheng Zhang</a></span>
                            </div>
                        </div>
                    </div>
                    <p class="research-desc">
                        Developing egocentric view driven end-to-end framework for predicting temporal future location prediction 
                        in 3D voxel scene representation along with precise & fine-grained affordance trajectory to interact with objects. 
                        This research enables long-horizon task planning in complex 3D environments.
                    </p>
                    <div class="research-tags">
                        <span class="tag primary">Egocentric Vision</span>
                        <span class="tag">Affordance Prediction</span>
                        <span class="tag">3D Scene Understanding</span>
                        <span class="tag">Long-horizon Planning</span>
                    </div>
                </div>

                <div class="research-card">
                    <div class="card-ribbon completed">COMPLETED</div>
                    <div class="research-header">
                        <div class="research-icon">üéØ</div>
                        <div class="research-meta">
                            <h3>HG-SCRUB: Human-Gaussian Scene Representation with Unified Baking</h3>
                            <div class="research-details">
                                <span class="research-date">Jan 2025 - May 2025</span>
                            </div>
                        </div>
                    </div>
                    <p class="research-desc">
                        Developed framework for human and scene decomposition in separate representations given sparse image frames from video. 
                        Successfully learned material and physical components (Normals, Albedo, Roughness & Metallic) with explicit normal 
                        learning using depth derivation and baking for human gaussians to be relighted based on scene's environment map.
                    </p>
                    <div class="research-tags">
                        <span class="tag primary">3D Gaussian Splatting</span>
                        <span class="tag">Material Decomposition</span>
                        <span class="tag">Neural Rendering</span>
                        <span class="tag">Human-Scene Separation</span>
                    </div>
                </div>

                <div class="research-card">
                    <div class="card-ribbon completed">COMPLETED</div>
                    <div class="research-header">
                        <div class="research-icon">üé¨</div>
                        <div class="research-meta">
                            <h3>Free-Generation: Training-Free Video Diffusion Control</h3>
                            <div class="research-details">
                                <span class="research-date">Aug 2024 - Dec 2024</span>
                                <span class="research-advisor">Advisor: <a href="https://czhang0528.github.io/" target="_blank">Prof. Cheng Zhang</a></span>
                            </div>
                        </div>
                    </div>
                    <p class="research-desc">
                        Conducted empirical research on Training-Free Trajectory Control Methods in Video Diffusion Models. 
                        Identified critical domain shifts in Attention Block Statistics and formulated innovative Statistical 
                        Post-Mask Normalization approaches for enhanced trajectory control performance.
                    </p>
                    <div class="research-tags">
                        <span class="tag primary">Video Diffusion</span>
                        <span class="tag">Trajectory Control</span>
                        <span class="tag">Attention Mechanisms</span>
                        <span class="tag">Training-Free Methods</span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Publications Section -->
    <section id="publications" class="section publications-section">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">PUBLICATIONS.db</h2>
                <div class="section-subtitle">Peer-Reviewed Research Output</div>
            </div>
            
            <div class="publications-grid">
                <div class="publication-card featured" data-abstract="The application of deep learning in visual anomaly detection has gained widespread popularity due to its potential use in quality control and manufacturing. Current standard methods are Unsupervised, where a clean dataset is utilised to detect deviations and flag anomalies during testing. However, incorporating a few samples when the type of anomalies is known beforehand can significantly enhance performance. Thus, we propose ATAC-Net, a framework that trains to detect anomalies from a minimal set of known prior anomalies. Furthermore, we introduce attention-guided cropping, which provides a closer view of suspect regions during the training phase. Our framework is a reliable and easy-to-understand system for detecting anomalies, and we substantiate its superiority to some of the current state-of-the-art techniques in a comparable setting.">
                    <div class="paper-badge spotlight">SPOTLIGHT</div>
                    <div class="paper-venue">ICIP 2024</div>
                    <h3 class="paper-title">ATAC-Net: Zoomed view works better for Anomaly Detection</h3>
                    <p class="paper-authors">Shaurya Gupta, <strong>Neil Gautam</strong>, Anurag Malyala</p>
                    <p class="paper-description">
                        Novel memory-based semi-supervised architecture achieving 98% catch rate with <1% false positive 
                        rate through attention-guided cropping for document tampering detection. Selected for spotlight presentation (top 5%).
                    </p>
                    <div class="paper-links">
                        <a href="https://ieeexplore.ieee.org/abstract/document/10647702" target="_blank" class="paper-link">
                            <span class="link-icon">üìÑ</span> Paper
                        </a>
                        <a href="#" class="paper-link">
                            <span class="link-icon">üíª</span> Code
                        </a>
                    </div>
                    <div class="paper-metrics">
                        <div class="metric">
                            <span class="metric-value">98%</span>
                            <span class="metric-label">Catch Rate</span>
                        </div>
                        <div class="metric">
                            <span class="metric-value"><1%</span>
                            <span class="metric-label">False Positive</span>
                        </div>
                    </div>
                </div>
                
                <div class="publication-card">
                    <div class="paper-venue">IEEE TCDS</div>
                    <h3 class="paper-title">Obscenity Detection in Videos through Sequential ConvNet Pipeline Classifier</h3>
                    <p class="paper-authors"><strong>Neil Gautam</strong>, Dr. Dinesh Kumar Vishwakarma</p>
                    <p class="paper-description">
                        Sequential ConvNet pipeline for automated video content moderation using temporal-spatial 
                        feature extraction and classification methodologies for real-time video analysis.
                    </p>
                    <div class="paper-links">
                        <a href="https://ieeexplore.ieee.org/abstract/document/9733936" target="_blank" class="paper-link">
                            <span class="link-icon">üìÑ</span> Paper
                        </a>
                    </div>
                </div>
                
                <div class="publication-card">
                    <div class="paper-venue">IEEE ICCMC</div>
                    <h3 class="paper-title">Ensemble Learning Using Vision Transformer and CNN for Person ReID</h3>
                    <p class="paper-authors">Gupta, <strong>Neil Gautam</strong>, Dr. Vishwakarma</p>
                    <p class="paper-description">
                        Novel ensemble approach combining Vision Transformers and CNNs for improved person 
                        re-identification performance across challenging scenarios and diverse datasets.
                    </p>
                    <div class="paper-links">
                        <a href="https://ieeexplore.ieee.org/abstract/document/9753761" target="_blank" class="paper-link">
                            <span class="link-icon">üìÑ</span> Paper
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Chronological Experience Timeline -->
    <section id="experience" class="section experience-section">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">EXPERIENCE_LOG.sys</h2>
                <div class="section-subtitle">From Research Labs to Production Systems</div>
            </div>
            
            <div class="timeline-experience">
                <div class="timeline-line"></div>
                
                <!-- Most Recent: 2025 -->
                <div class="timeline-experience-item current">
                    <div class="timeline-dot active">
                        <div class="dot-pulse"></div>
                    </div>
                    <div class="experience-content">
                        <div class="experience-card-timeline research">
                            <div class="card-status current">CURRENT</div>
                            <div class="experience-header-timeline">
                                <div class="role-icon-timeline">ü§ñ</div>
                                <div class="role-details">
                                    <h3>Research Intern, AI4Arch</h3>
                                    <div class="role-meta-timeline">
                                        <span class="company-name">Texas A&M University</span>
                                        <span class="time-period">June 2025 - August 2025</span>
                                    </div>
                                    <div class="advisors-info">
                                        <span>Advisors: <a href="https://czhang0528.github.io/" target="_blank">Dr. Cheng Zhang</a> & Dr. Roxana Jafari</span>
                                    </div>
                                </div>
                            </div>
                            
                            <div class="role-description-timeline">
                                <p>Advanced multi-view detection and tracking systems for real-time healthcare monitoring solutions using cutting-edge computer vision techniques. Pioneered real-time people tracking and re-identification in Intensive Healthcare Units.</p>
                            </div>
                            
                            <div class="tech-stack-timeline">
                                <div class="tech-label">Technologies Used:</div>
                                <div class="tech-chips">
                                    <span class="tech-chip">PyTorch</span>
                                    <span class="tech-chip">YOLOv11</span>
                                    <span class="tech-chip">ONNX</span>
                                    <span class="tech-chip">SMPL</span>
                                </div>
                            </div>
                            
                            <div class="achievements-timeline">
                                <div class="achievement-header">Key Contributions & Achievements:</div>
                                <ul class="achievement-list">
                                    <li><span class="bullet">‚ñ∏</span> Developed multi-view detection (YOLOv11) & tracking algorithm based on generative feature templates for tracking & re-identifying people in Intensive Healthcare Units in real-time</li>
                                    <li><span class="bullet">‚ñ∏</span> Constructed observed 3D Scene with objects using multi-view input for representing humans in 3D (SMPL) to flag harmful behavior according to health codes</li>
                                    <li><span class="bullet">‚ñ∏</span> Implemented SMPL-based 3D human representation for automated health code compliance monitoring</li>
                                    <li><span class="bullet">‚ñ∏</span> Advanced computer vision pipeline for healthcare applications with real-time processing capabilities</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- 2024-Present -->
                <div class="timeline-experience-item">
                    <div class="timeline-dot ongoing"></div>
                    <div class="experience-content">
                        <div class="experience-card-timeline research">
                            <div class="card-status ongoing">ONGOING</div>
                            <div class="experience-header-timeline">
                                <div class="role-icon-timeline">ü´Ä</div>
                                <div class="role-details">
                                    <h3>Student Assistant, C2B Lab</h3>
                                    <div class="role-meta-timeline">
                                        <span class="company-name">Texas A&M University</span>
                                        <span class="time-period">Sep 2024 - Present</span>
                                    </div>
                                    <div class="advisors-info">
                                        <span>Advisor: <a href="https://engineering.tamu.edu/biomedical/profiles/avazmohammadi-reza.html" target="_blank">Dr. Reza Avazmohammadi</a></span>
                                    </div>
                                </div>
                            </div>
                            
                            <div class="role-description-timeline">
                                <p>Developing 4D heart motion tracking systems using diffusion models for non-invasive cardiac analysis. Pioneering advanced medical imaging applications through novel machine learning approaches.</p>
                            </div>
                            
                            <div class="tech-stack-timeline">
                                <div class="tech-label">Technologies Used:</div>
                                <div class="tech-chips">
                                    <span class="tech-chip">PyTorch</span>
                                    <span class="tech-chip">Matlab</span>
                                    <span class="tech-chip">Python</span>
                                    <span class="tech-chip">Viser</span>
                                </div>
                            </div>
                            
                            <div class="achievements-timeline">
                                <div class="achievement-header">Key Contributions & Achievements:</div>
                                <ul class="achievement-list">
                                    <li><span class="bullet">‚ñ∏</span> Currently working on 4D Motion tracking of Heart by mapping 2D based motion to 3D using motion interpolation techniques</li>
                                    <li><span class="bullet">‚ñ∏</span> Devised novel Semi-Supervised Diffusion based Image Registration approach for achieving 2D motion tracking of Rat's Heart</li>
                                    <li><span class="bullet">‚ñ∏</span> Developed Geometry aware (2D slice prior) Diffusion based 3D Reconstruction Model for precise mesh generation of Rat's Heart</li>
                                    <li><span class="bullet">‚ñ∏</span> Advanced cardiac motion analysis from echo images for non-invasive disease prediction solutions</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- 2024 -->
                <div class="timeline-experience-item">
                    <div class="timeline-dot completed"></div>
                    <div class="experience-content">
                        <div class="experience-card-timeline industry">
                            <div class="card-status completed">COMPLETED</div>
                            <div class="experience-header-timeline">
                                <div class="role-icon-timeline">üé®</div>
                                <div class="role-details">
                                    <h3>Machine Learning Engineer-2</h3>
                                    <div class="role-meta-timeline">
                                        <span class="company-name">AfterShoot</span>
                                        <span class="time-period">Nov 2023 - Jul 2024</span>
                                    </div>
                                    <div class="advisors-info">
                                        <span>Manager: <a href="https://www.linkedin.com/in/nikhil-bartwal-b07b501a3/" target="_blank">Nikhil Bartwal</a></span>
                                    </div>
                                </div>
                            </div>
                            
                            <div class="impact-metrics-timeline">
                                <div class="impact-item">
                                    <span class="impact-number">40%</span>
                                    <span class="impact-label">Workflow Acceleration</span>
                                </div>
                                <div class="impact-item">
                                    <span class="impact-number">10h‚Üí3h</span>
                                    <span class="impact-label">Processing Time</span>
                                </div>
                                <div class="impact-item">
                                    <span class="impact-number">1000+</span>
                                    <span class="impact-label">Photos Enhanced</span>
                                </div>
                            </div>
                            
                            <div class="role-description-timeline">
                                <p>Spearheaded development of AI portrait enhancement and retouching systems, delivering production-grade features that revolutionized photo editing workflows for professional photographers.</p>
                            </div>
                            
                            <div class="tech-stack-timeline">
                                <div class="tech-label">Technologies Used:</div>
                                <div class="tech-chips">
                                    <span class="tech-chip">Python</span>
                                    <span class="tech-chip">C++</span>
                                    <span class="tech-chip">Rust</span>
                                    <span class="tech-chip">RunPod</span>
                                    <span class="tech-chip">GCP</span>
                                    <span class="tech-chip">Azure</span>
                                    <span class="tech-chip">PyTorch</span>
                                    <span class="tech-chip">TensorFlow</span>
                                </div>
                            </div>
                            
                            <div class="achievements-timeline">
                                <div class="achievement-header">Key Contributions & Achievements:</div>
                                <ul class="achievement-list">
                                    <li><span class="bullet">‚ñ∏</span> Spearheaded development of AI portrait enhancement and retouching, delivering features such as teeth correction, whitening, skin retouching. This product reduced photoshop time from approximately 10s of hours to < 2-3 hours for around 1000 photos</li>
                                    <li><span class="bullet">‚ñ∏</span> Engineered and deployed U-Net based generative model that allowed generative teeth correction capabilities in portrait photos</li>
                                    <li><span class="bullet">‚ñ∏</span> Accelerated photo editing workflow by 40% by designing lightweight models automating HSL filters in Lightroom Classic</li>
                                    <li><span class="bullet">‚ñ∏</span> Deployed production-scale computer vision systems serving thousands of professional photographers</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- 2023 -->
                <div class="timeline-experience-item">
                    <div class="timeline-dot completed"></div>
                    <div class="experience-content">
                        <div class="experience-card-timeline industry">
                            <div class="card-status completed">COMPLETED</div>
                            <div class="experience-header-timeline">
                                <div class="role-icon-timeline">üìà</div>
                                <div class="role-details">
                                    <h3>Machine Learning Engineer</h3>
                                    <div class="role-meta-timeline">
                                        <span class="company-name">Savart</span>
                                        <span class="time-period">Jan 2023 - Oct 2023</span>
                                    </div>
                                    <div class="advisors-info">
                                        <span>Manager: <a href="https://www.linkedin.com/in/suhruth-eedara-93858412b/" target="_blank">Suhruth Eedara</a></span>
                                    </div>
                                </div>
                            </div>
                            
                            <div class="impact-metrics-timeline">
                                <div class="impact-item">
                                    <span class="impact-number">35%</span>
                                    <span class="impact-label">QA Accuracy Boost</span>
                                </div>
                                <div class="impact-item">
                                    <span class="impact-number">50K+</span>
                                    <span class="impact-label">Documents Processed</span>
                                </div>
                                <div class="impact-item">
                                    <span class="impact-number">Weeks‚ÜíDays</span>
                                    <span class="impact-label">Analysis Time</span>
                                </div>
                            </div>
                            
                            <div class="role-description-timeline">
                                <p>Fine-tuned large language models on financial reports and developed advanced NLP pipelines, revolutionizing equity market analysis through automated document processing and intelligent information extraction.</p>
                            </div>
                            
                            <div class="tech-stack-timeline">
                                <div class="tech-label">Technologies Used:</div>
                                <div class="tech-chips">
                                    <span class="tech-chip">Python</span>
                                    <span class="tech-chip">C++</span>
                                    <span class="tech-chip">AWS</span>
                                    <span class="tech-chip">GCP</span>
                                    <span class="tech-chip">Azure</span>
                                    <span class="tech-chip">PyTorch</span>
                                </div>
                            </div>
                            
                            <div class="achievements-timeline">
                                <div class="achievement-header">Key Contributions & Achievements:</div>
                                <ul class="achievement-list">
                                    <li><span class="bullet">‚ñ∏</span> Fine-tuned LLAMA-2 and Alpaca models on financial annual reports that boosted qualitative company profiling capabilities to be used in equity market analysis. Boosted the efficiency of Equity market research from weeks to days</li>
                                    <li><span class="bullet">‚ñ∏</span> Engineered dynamic OCR pipeline & automated information extraction. Processing more than 50K documents for corpus creation</li>
                                    <li><span class="bullet">‚ñ∏</span> Enhanced QA accuracy by 35% through strategic optimization of reader models (RoBERTa, BART, XLM) on novel dataset</li>
                                    <li><span class="bullet">‚ñ∏</span> Developed scalable NLP systems for financial document analysis and automated reporting</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- 2022 -->
                <div class="timeline-experience-item">
                    <div class="timeline-dot completed"></div>
                    <div class="experience-content">
                        <div class="experience-card-timeline research-intern">
                            <div class="card-status spotlight">SPOTLIGHT</div>
                            <div class="experience-header-timeline">
                                <div class="role-icon-timeline">üîç</div>
                                <div class="role-details">
                                    <h3>Deep Learning Research Intern</h3>
                                    <div class="role-meta-timeline">
                                        <span class="company-name">HyperVerge Ltd</span>
                                        <span class="time-period">Jul 2022 - Dec 2022</span>
                                    </div>
                                    <div class="advisors-info">
                                        <span>Supervisor: <a href="https://www.linkedin.com/in/hariprasad-p-s-162b0778/" target="_blank">Hariprasad P S</a></span>
                                    </div>
                                </div>
                            </div>
                            
                            <div class="impact-metrics-timeline">
                                <div class="impact-item">
                                    <span class="impact-number">98%</span>
                                    <span class="impact-label">Catch Rate</span>
                                </div>
                                <div class="impact-item">
                                    <span class="impact-number"><1%</span>
                                    <span class="impact-label">False Positive</span>
                                </div>
                                <div class="impact-item">
                                    <span class="impact-number">100+</span>
                                    <span class="impact-label">Global Clients</span>
                                </div>
                            </div>
                            
                            <div class="role-description-timeline">
                                <p>Led R&D for industry-leading document tampering detection systems serving global markets. Developed novel anomaly detection architecture that achieved unprecedented accuracy rates and was selected for prestigious academic recognition.</p>
                            </div>
                            
                            <div class="achievements-timeline">
                                <div class="achievement-header">Key Contributions & Achievements:</div>
                                <ul class="achievement-list">
                                    <li><span class="bullet">‚ñ∏</span> Spearheaded R&D for industry-leading ID tampering detection system serving over 100 clients with state-of-the-art tampering detection system</li>
                                    <li><span class="bullet">‚ñ∏</span> Developed tampering detection system that achieved an unprecedented 98% catch rate with less than 1% false positive rate</li>
                                    <li><span class="bullet">‚ñ∏</span> Proposed a novel anomaly detection approach (ATAC-Net) using memory-based semi-supervised architecture after experimenting with MemSeg, DeviationNet, WS-DAN to create precise tampering localization in documents across diverse document types</li>
                                    <li><span class="bullet">‚ñ∏</span> This work was selected among the best 5% and chosen for the spotlight presentation at ICIP 2024</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Contact Section -->
    <section id="contact" class="section contact-section">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">INITIALIZE_CONTACT.run</h2>
                <div class="section-subtitle">Ready to push the boundaries of AI research?</div>
            </div>
            
            <div class="contact-grid">
                <div class="contact-terminal">
                    <div class="terminal-header">
                        <div class="terminal-controls">
                            <span class="control red"></span>
                            <span class="control yellow"></span>
                            <span class="control green"></span>
                        </div>
                        <div class="terminal-title">connection_established.py</div>
                    </div>
                    <div class="terminal-content">
                        <div class="contact-command">
                            <span class="prompt">$</span> <span class="command">establish_connection --mode=collaboration</span>
                        </div>
                        <div class="contact-output">
                            <div class="output-line">Establishing secure neural link...</div>
                            <div class="output-line success">‚úì Connection established</div>
                            <div class="output-line">Ready for research collaboration</div>
                        </div>
                        
                        <div class="contact-methods">
                            <a href="mailto:neilgautam.24@tamu.edu" class="contact-method primary">
                                <div class="method-icon">@</div>
                                <div class="method-info">
                                    <div class="method-label">Primary Channel</div>
                                    <div class="method-value">neilgautam.24@tamu.edu</div>
                                </div>
                            </a>
                            
                            <a href="https://www.linkedin.com/in/neil-gautam-a928971a5/" target="_blank" class="contact-method">
                                <div class="method-icon">IN</div>
                                <div class="method-info">
                                    <div class="method-label">Professional Network</div>
                                    <div class="method-value">LinkedIn Profile</div>
                                </div>
                            </a>
                            
                            <a href="https://github.com/neilgautam24-tamu" target="_blank" class="contact-method">
                                <div class="method-icon">{ }</div>
                                <div class="method-info">
                                    <div class="method-label">Code Repository</div>
                                    <div class="method-value">GitHub Portfolio</div>
                                </div>
                            </a>
                            
                            <a href="https://scholar.google.com/citations?user=CUISVw8AAAAJ&hl=en" target="_blank" class="contact-method">
                                <div class="method-icon">üìö</div>
                                <div class="method-info">
                                    <div class="method-label">Research Publications</div>
                                    <div class="method-value">Google Scholar</div>
                                </div>
                            </a>
                        </div>
                        
                        <div class="location-info">
                            <div class="location-line">
                                <span class="prompt">$</span> <span class="command">get_location</span>
                            </div>
                            <div class="location-output">
                                üìç College Station, TX | Texas A&M University<br>
                                üéì MS Computer Science, GPA: 4.0/4.0<br>
                                üì± Phone: +1 (979) 721-3148<br>
                                üî¨ Research Focus: Embodied AI, Human-Centric Vision, Medical Imaging
                            </div>
                        </div>
                    </div>
                </div>
                
                <div class="education-summary">
                    <div class="edu-card current">
                        <div class="edu-header">
                            <div class="edu-icon">üéì</div>
                            <div class="edu-info">
                                <h3>Master of Science in Computer Science</h3>
                                <div class="edu-school">Texas A&M University</div>
                                <div class="edu-duration">Aug 2024 - Jun 2026 (Expected)</div>
                            </div>
                            <div class="edu-gpa perfect">4.0</div>
                        </div>
                        
                        <div class="coursework-grid">
                            <div class="course-category">
                                <div class="category-label">Current (Fall 2025)</div>
                                <div class="course-pills">
                                    <span class="course-pill active">Deep Reinforcement Learning</span>
                                    <span class="course-pill active">Generative AI</span>
                                    <span class="course-pill active">Research</span>
                                </div>
                            </div>
                            
                            <div class="course-category">
                                <div class="category-label">Completed Coursework</div>
                                <div class="course-pills">
                                    <span class="course-pill completed">Vision Foundation Models</span>
                                    <span class="course-pill completed">ML for 3D Visualization & Graphics</span>
                                    <span class="course-pill completed">Machine Learning</span>
                                    <span class="course-pill completed">Analysis of Algorithms</span>
                                    <span class="course-pill completed">Software Engineering</span>
                                    <span class="course-pill completed">Distributed Systems & Cloud Computing</span>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <div class="edu-card">
                        <div class="edu-header">
                            <div class="edu-icon">üéØ</div>
                            <div class="edu-info">
                                <h3>Bachelor of Technology (B.Tech)</h3>
                                <div class="edu-school">Delhi Technological University</div>
                                <div class="edu-duration">Aug 2018 - May 2022</div>
                            </div>
                            <div class="edu-gpa high">8.6</div>
                        </div>
                        <div class="edu-details">
                            <p><strong>Major:</strong> Information Technology</p>
                            <p><strong>Location:</strong> Delhi, India</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Abstract Tooltip -->
    <div id="abstract-tooltip" class="abstract-tooltip">
        <div class="tooltip-header">PAPER_ABSTRACT.txt</div>
        <div class="tooltip-content">
            <p id="tooltip-text"></p>
        </div>
    </div>

    <!-- Scroll Progress Indicator -->
    <div class="scroll-progress">
        <div class="progress-bar"></div>
    </div>

    <script src="script.js"></script>
</body>
</html>
