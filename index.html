<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neil Gautam - ML Researcher</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <!-- Header -->
    <header class="header">
        <div class="container">
            <h1 class="name">Neil Gautam</h1>
            <p class="title">Machine Learning Researcher</p>
            <div class="contact-info">
                <span>neilgautam.24@tamu.edu</span>
                <span>•</span>
                <span>+1 (979) 721-3148</span>
                <span>•</span>
                <span>College Station, TX</span>
            </div>
            <div class="links">
                <a href="https://linkedin.com/in/neil-gautam-a928971a5" target="_blank">LinkedIn</a>
                <a href="https://github.com/neilgautam-24" target="_blank">GitHub</a>
                <a href="https://scholar.google.com" target="_blank">Google Scholar</a>
            </div>
        </div>
    </header>

    <!-- Main Content -->
    <main class="main">
        <div class="container">
            <!-- About Section -->
            <section class="section" id="about">
                <div class="section-container">
                    <h2 class="section-title">About</h2>
                    <div class="section-content">
                        <p class="intro">
                            I am an MS in Computer Science student at Texas A&M University (GPA: 4.0/4.0) specializing in 
                            <strong>Computer Vision</strong>, <strong>3D Reconstruction</strong>, and <strong>Diffusion Models</strong>. 
                            My research focuses on developing novel approaches for egocentric scene understanding, medical imaging, 
                            and bridging the gap between theoretical ML breakthroughs and real-world applications.
                        </p>
                        <p class="intro">
                            Under the supervision of <strong>Prof. Cheng Zhang</strong>, I work on holistic human scene/object 
                            understanding and manipulation. Additionally, I contribute to medical imaging research at the C2B Lab 
                            under <strong>Dr. Reza Avazmohammadi</strong>, developing diffusion-based approaches for 4D heart motion 
                            tracking and image registration.
                        </p>
                    </div>
                </div>
            </section>

            <!-- Research Philosophy -->
            <section class="section" id="philosophy">
                <div class="section-container">
                    <h2 class="section-title">Research Philosophy</h2>
                    <div class="section-content">
                        <div class="philosophy-card">
                            <p class="philosophy-text">
                                "I am driven by the opportunity to bridge theoretical breakthroughs with solutions that genuinely 
                                improve people's lives. Whether developing novel architectures for medical imaging or deploying 
                                scalable ML systems, I thrive on turning ambitious ideas into production reality while pushing 
                                the boundaries of what's possible with machine learning."
                            </p>
                        </div>
                        <div class="research-interests">
                            <h3>Research Interests</h3>
                            <div class="interests-grid">
                                <span class="interest-tag">Computer Vision</span>
                                <span class="interest-tag">3D Reconstruction</span>
                                <span class="interest-tag">Diffusion Models</span>
                                <span class="interest-tag">Medical Imaging</span>
                                <span class="interest-tag">Scene Understanding</span>
                                <span class="interest-tag">Gaussian Splatting</span>
                                <span class="interest-tag">NeRF</span>
                                <span class="interest-tag">Anomaly Detection</span>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Research Projects Section -->
            <section class="section" id="research">
                <div class="section-container">
                    <h2 class="section-title">Research Projects</h2>
                    <div class="section-content">
                        <div class="research-item featured">
                            <div class="research-header">
                                <h3>Holistic Human (Body & Hand) Scene/Object Understanding and Manipulation</h3>
                                <span class="date">May 2025 - Present</span>
                            </div>
                            <div class="research-details">
                                <p><strong>Advisor:</strong> Prof. Cheng Zhang (Main Advisor) | <strong>Status:</strong> Ongoing Research</p>
                                <p>Developing a text-driven framework for scene/object interaction and manipulation for sequential 
                                and concurrent long tasks with dexterous hand control and scene understanding. This work aims to 
                                enable more natural human-computer interaction through comprehensive understanding of both human 
                                body dynamics and environmental context.</p>
                                <div class="keywords">
                                    <span class="keyword">Scene Understanding</span>
                                    <span class="keyword">Human Motion</span>
                                    <span class="keyword">Object Manipulation</span>
                                </div>
                            </div>
                        </div>

                        <div class="research-item">
                            <div class="research-header">
                                <h3>HG-SCRUB: Human-Gaussian Scene Representation with Unified Baking</h3>
                                <span class="date">Jan 2025 - May 2025</span>
                            </div>
                            <div class="research-details">
                                <p><strong>Status:</strong> Under Review</p>
                                <p>Developed a novel framework achieving decomposition of human and scene in separate representations 
                                while learning their material and physical components (Normals, Albedo, Roughness, Metallic). 
                                Implemented explicit normal learning using depth derivation-based gradients and applied baking 
                                for human Gaussians to model indirect illumination.</p>
                                <div class="keywords">
                                    <span class="keyword">3D Gaussian Splatting</span>
                                    <span class="keyword">Material Decomposition</span>
                                    <span class="keyword">Neural Rendering</span>
                                </div>
                            </div>
                        </div>

                        <div class="research-item">
                            <div class="research-header">
                                <h3>Free-Generation: Training-Free Trajectory Control in Video Diffusion</h3>
                                <span class="date">Aug 2024 - Dec 2024</span>
                            </div>
                            <div class="research-details">
                                <p><strong>Advisor:</strong> Prof. Cheng Zhang | <strong>Status:</strong> Completed</p>
                                <p>Conducted empirical research on Training-Free Trajectory Control Methods in Video Diffusion Models, 
                                identifying critical domain shifts in Attention Block Statistics. Formulated innovative Statistical 
                                Post-Mask Normalization approaches that significantly enhanced run-time trajectory control performance.</p>
                                <div class="keywords">
                                    <span class="keyword">Video Diffusion</span>
                                    <span class="keyword">Trajectory Control</span>
                                    <span class="keyword">Attention Mechanisms</span>
                                </div>
                            </div>
                        </div>

                        <div class="research-item">
                            <div class="research-header">
                                <h3>4D Heart Motion Tracking & Diffusion-Based Medical Imaging</h3>
                                <span class="date">Sep 2024 - Present</span>
                            </div>
                            <div class="research-details">
                                <p><strong>Advisor:</strong> Dr. Reza Avazmohammadi (C2B Lab) | <strong>Status:</strong> Ongoing</p>
                                <p>Developing 4D motion tracking of heart by mapping 2D-based motion to 3D using motion interpolation. 
                                Devised novel Semi-Supervised Diffusion-based Image Registration approach for 2D motion tracking 
                                of rat hearts. Created geometry-aware diffusion-based 3D reconstruction model for precise mesh generation.</p>
                                <div class="keywords">
                                    <span class="keyword">Medical Imaging</span>
                                    <span class="keyword">Diffusion Models</span>
                                    <span class="keyword">4D Reconstruction</span>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Publications Section -->
            <section class="section" id="publications">
                <div class="section-container">
                    <h2 class="section-title">Publications</h2>
                    <div class="section-content">
                        <div class="publication-item featured">
                            <div class="pub-badge spotlight">SPOTLIGHT PRESENTATION</div>
                            <h3>ATAC-Net: Zoomed view works better for Anomaly Detection</h3>
                            <p class="authors"><strong>Shaurya Gupta, Neil Gautam, Anurag Malyala</strong></p>
                            <p class="venue">IEEE International Conference on Image Processing (ICIP) 2024</p>
                            <p class="description">
                                Proposed a novel memory-based semi-supervised architecture for document tampering detection, 
                                achieving 98% catch rate with <1% false positive rate. Processes 15M+ monthly requests globally.
                            </p>
                            <div class="publication-links">
                                <a href="#" class="pub-link">Paper</a>
                                <a href="#" class="pub-link">Code</a>
                                <a href="#" class="pub-link">Project Page</a>
                            </div>
                        </div>

                        <div class="publication-item">
                            <h3>Obscenity Detection in Videos through a Sequential ConvNet Pipeline Classifier</h3>
                            <p class="authors"><strong>Neil Gautam, Dr. Dinesh Kumar Vishwakarma</strong></p>
                            <p class="venue">IEEE Transactions on Cognitive and Developmental Systems (TCDS)</p>
                            <p class="description">
                                Developed a sequential ConvNet pipeline for automated video content moderation using 
                                temporal-spatial feature extraction and classification.
                            </p>
                            <div class="publication-links">
                                <a href="#" class="pub-link">Paper</a>
                            </div>
                        </div>

                        <div class="publication-item">
                            <h3>Ensemble Learning Using Vision Transformer and Convolutional Network for Person ReID</h3>
                            <p class="authors"><strong>Gupta, Neil Gautam, Dr. Vishwakarma</strong></p>
                            <p class="venue">IEEE International Conference on Computing, Communication and Multimedia Computing (ICCMC)</p>
                            <p class="description">
                                Novel ensemble approach combining Vision Transformers and CNNs for improved person re-identification 
                                performance across challenging scenarios.
                            </p>
                            <div class="publication-links">
                                <a href="#" class="pub-link">Paper</a>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Education & Current Coursework -->
            <section class="section" id="education">
                <div class="section-container">
                    <h2 class="section-title">Education & Current Studies</h2>
                    <div class="section-content">
                        <div class="education-item">
                            <div class="education-header">
                                <h3>Master of Science in Computer Science</h3>
                                <span class="date">Aug 2024 - Jun 2026 (Expected)</span>
                            </div>
                            <div class="education-details">
                                <p><strong>Texas A&M University</strong>, College Station, TX</p>
                                <p><strong>GPA:</strong> 4.0/4.0 | <strong>Concentration:</strong> Thesis Option</p>
                                
                                <div class="coursework-section">
                                    <h4>Current Coursework (Fall 2025)</h4>
                                    <div class="course-grid">
                                        <div class="course-item">
                                            <span class="course-code">CSCE 642</span>
                                            <span class="course-name">Deep Reinforcement Learning</span>
                                        </div>
                                        <div class="course-item">
                                            <span class="course-code">CSCE 689</span>
                                            <span class="course-name">Special Topics: Generative AI</span>
                                        </div>
                                        <div class="course-item">
                                            <span class="course-code">CSCE 691</span>
                                            <span class="course-name">Research</span>
                                        </div>
                                    </div>
                                </div>

                                <div class="coursework-section">
                                    <h4>Completed Coursework</h4>
                                    <div class="course-grid">
                                        <div class="course-item completed">
                                            <span class="course-code">CSCE 689</span>
                                            <span class="course-name">Vision Foundation Models</span>
                                            <span class="grade">A</span>
                                        </div>
                                        <div class="course-item completed">
                                            <span class="course-code">CSCE 689</span>
                                            <span class="course-name">ML for 3D Visualization & Graphics</span>
                                            <span class="grade">A</span>
                                        </div>
                                        <div class="course-item completed">
                                            <span class="course-code">CSCE 633</span>
                                            <span class="course-name">Machine Learning</span>
                                            <span class="grade">A</span>
                                        </div>
                                        <div class="course-item completed">
                                            <span class="course-code">CSCE 629</span>
                                            <span class="course-name">Analysis of Algorithms</span>
                                            <span class="grade">A</span>
                                        </div>
                                        <div class="course-item completed">
                                            <span class="course-code">CSCE 606</span>
                                            <span class="course-name">Software Engineering</span>
                                            <span class="grade">A</span>
                                        </div>
                                        <div class="course-item completed">
                                            <span class="course-code">ECEN 757</span>
                                            <span class="course-name">Distributed Systems & Cloud Computing</span>
                                            <span class="grade">A</span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <div class="education-item">
                            <div class="education-header">
                                <h3>Bachelor of Technology (B.Tech), Information Technology</h3>
                                <span class="date">Aug 2018 - May 2022</span>
                            </div>
                            <div class="education-details">
                                <p><strong>Delhi Technological University</strong>, Delhi, India</p>
                                <p><strong>GPA:</strong> 8.6/10.0</p>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Research Experience & Industry -->
            <section class="section" id="experience">
                <div class="section-container">
                    <h2 class="section-title">Research & Industry Experience</h2>
                    <div class="section-content">

                        <div class="experience-item research">
                            <div class="experience-header">
                                <h3>Graduate Research Assistant</h3>
                                <span class="date">May 2025 - Present</span>
                            </div>
                            <div class="experience-details">
                                <p><strong>Advisor:</strong> Prof. Cheng Zhang | <strong>Texas A&M University</strong></p>
                                <p><strong>Focus:</strong> Computer Vision, 3D Scene Understanding, Human Motion Analysis</p>
                                <ul>
                                    <li>Leading research on text-driven frameworks for holistic human-scene interaction and manipulation</li>
                                    <li>Developing novel approaches for egocentric scene understanding with dexterous hand control</li>
                                    <li>Advancing state-of-the-art in sequential and concurrent task execution in 3D environments</li>
                                </ul>
                            </div>
                        </div>

                        <div class="experience-item research">
                            <div class="experience-header">
                                <h3>Student Assistant, C2B Lab (Part-time)</h3>
                                <span class="date">Sep 2024 - Present</span>
                            </div>
                            <div class="experience-details">
                                <p><strong>Advisor:</strong> Dr. Reza Avazmohammadi | <strong>Texas A&M University</strong></p>
                                <p><strong>Technologies:</strong> PyTorch, Matlab, Python</p>
                                <ul>
                                    <li>Developing 4D motion tracking of heart by mapping 2D-based motion to 3D using motion interpolation</li>
                                    <li>Devised novel Semi-Supervised Diffusion-based Image Registration for 2D motion tracking of rat hearts</li>
                                    <li>Created geometry-aware diffusion-based 3D reconstruction model for precise heart mesh generation</li>
                                </ul>
                            </div>
                        </div>

                        <div class="experience-item industry">
                            <div class="experience-header">
                                <h3>Machine Learning Engineer-2, AfterShoot</h3>
                                <span class="date">Nov 2023 - Jul 2024</span>
                            </div>
                            <div class="experience-details">
                                <p><strong>Technologies:</strong> Python, C++, Rust, RunPod, GCP, Azure, PyTorch, TensorFlow</p>
                                <p><strong>Impact:</strong> Reduced photo editing time from 10+ hours to <3 hours for 1000+ photos</p>
                                <ul>
                                    <li>Spearheaded AI portrait enhancement solutions: teeth correction, whitening, skin retouching</li>
                                    <li>Engineered and deployed U-Net based generative model for portrait photo enhancement</li>
                                    <li>Accelerated photo editing workflow by 40% through lightweight automated HSL filter models</li>
                                </ul>
                            </div>
                        </div>

                        <div class="experience-item industry">
                            <div class="experience-header">
                                <h3>Machine Learning Engineer, Savart</h3>
                                <span class="date">Jan 2023 - Oct 2023</span>
                            </div>
                            <div class="experience-details">
                                <p><strong>Technologies:</strong> Python, C++, AWS, GCP, Azure, PyTorch</p>
                                <p><strong>Impact:</strong> Reduced equity market research time from weeks to days</p>
                                <ul>
                                    <li>Fine-tuned LLAMA-2 and Alpaca models on financial reports for equity market analysis</li>
                                    <li>Engineered dynamic OCR pipeline processing 50K+ documents for corpus creation</li>
                                    <li>Enhanced QA accuracy by 35% through strategic optimization of reader models (RoBERTa, BART, XLM)</li>
                                </ul>
                            </div>
                        </div>

                        <div class="experience-item research-intern">
                            <div class="experience-header">
                                <h3>Deep Learning Research Intern, HyperVerge Ltd</h3>
                                <span class="date">Jul 2022 - Dec 2022</span>
                            </div>
                            <div class="experience-details">
                                <p><strong>Supervisor:</strong> Hariprasad P S | <strong>Impact:</strong> 15M+ monthly requests globally</p>
                                <ul>
                                    <li>Led R&D for industry-leading ID tampering detection system serving 100+ global clients</li>
                                    <li>Achieved unprecedented 98% catch rate with <1% false positive rate in tampering detection</li>
                                    <li>Developed ATAC-Net: novel anomaly detection approach selected for ICIP 2024 spotlight (top 5%)</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Technical Skills Section -->
            <section class="section" id="skills">
                <div class="section-container">
                    <h2 class="section-title">Technical Expertise</h2>
                    <div class="section-content">
                        <div class="skills-grid">
                            <div class="skill-category primary">
                                <h3>Research Domains</h3>
                                <p>Computer Vision, 3D Reconstruction, Diffusion Models, Medical Imaging, Scene Understanding, 
                                Gaussian Splatting, NeRF, Anomaly Detection</p>
                            </div>
                            <div class="skill-category">
                                <h3>Deep Learning</h3>
                                <p>PyTorch, TensorFlow, Keras, Hugging Face Transformers, Diffusion Models, CNNs, RNNs, 
                                Vision Transformers, Attention Mechanisms</p>
                            </div>
                            <div class="skill-category">
                                <h3>Computer Vision</h3>
                                <p>OpenCV, Open3D, Pyvista, Image Processing, 3D Gaussian Splatting, NeRF, Medical Imaging, 
                                Object Detection, Semantic Segmentation</p>
                            </div>
                            <div class="skill-category">
                                <h3>NLP & LLMs</h3>
                                <p>LLAMA-2, Alpaca, BERT, RoBERTa, BART, XLM, Extractive QA, Text-to-3D, 
                                Fine-tuning, Prompt Engineering</p>
                            </div>
                            <div class="skill-category">
                                <h3>Programming</h3>
                                <p>Python, C++, JavaScript, Ruby, SQL, Rust, Matlab, CUDA, OpenMP</p>
                            </div>
                            <div class="skill-category">
                                <h3>Research Tools</h3>
                                <p>scikit-learn, Pandas, Matplotlib, Jupyter, Docker, Git, LaTeX, 
                                AWS, Google Cloud, Azure</p>
                            </div>
                        </div>
                    </div>
                </div>
            </section>
        </div>
    </main>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>&copy; 2025 Neil Gautam. All rights reserved.</p>
        </div>
    </footer>
</body>
</html>
