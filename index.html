<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Neil Gautam | AI Researcher</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link href="styles.css" rel="stylesheet">
  <link href="https://cdnjs.cloudflare.com/ajax/libs/bootstrap-icons/1.10.3/font/bootstrap-icons.min.css" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
</head>
<body>

<nav class="top-nav">
  <div class="nav-container">
    <div class="nav-brand">Neil Gautam</div>
    <div class="nav-items">
      <a href="#home" class="nav-item active">HOME</a>
      <a href="#profile" class="nav-item">PROFILE</a>
      <a href="#experience" class="nav-item">EXPERIENCE</a>
      <a href="#research" class="nav-item">RESEARCH</a>
      <a href="#publications" class="nav-item">PUBLICATIONS</a>
      <a href="#contact" class="nav-item">CONTACT</a>
    </div>
  </div>
</nav>

<main>
  <!-- Home / Intro -->
  <section id="home" class="section hero-section">
    <div class="container hero-flex">
      <div>
        <span class="block-label">$ whoami</span>
        <h1>Neil Gautam</h1>
        <div class="subtitle">AI Researcher</div>
        <div class="topic-tags">Embodied AI &bullet; Human-Centric Computer Vision &bullet; Egocentric Systems</div>
        <div class="about-research">
          <span class="block-label">$ cat research_focus.txt</span>
          <div class="research-summary">
            <p>My research interest lies at the intersection of embodied AI and human-centric computer vision, where I develop intelligent systems that can understand and predict how humans perceive, navigate, and interact with complex 3D environments. Drawing from my experience building production-scale vision systems and generative models, I've evolved toward addressing fundamental questions about human behavior prediction and spatial scene understanding.</p>
            <p>My current focus centers on egocentric vision and affordance modeling—developing frameworks that move beyond traditional computer vision to predict how humans will interact with their environment over time, bridging 2D visual perception with 3D spatial reasoning through advanced generative architectures, particularly diffusion models applied across diverse domains from healthcare to robust vision systems.</p>
            <p>What drives my research is the conviction that truly intelligent AI must understand the intentionality behind human actions, not just recognize visual patterns. My interdisciplinary approach combines computer vision, generative AI, and biomedical applications, positioning me to tackle fundamental challenges in embodied AI where spatial-temporal understanding of human behavior is critical. Whether developing memory-based architectures for anomaly detection, real-time monitoring systems that construct 3D scene representations, or geometry-aware reconstruction models for medical imaging analysis, I'm consistently working toward AI systems that don't just process visual data, but comprehend the physics, intentionality, and temporal dynamics of how humans move through and interact with their world—creating AI that truly understands human behavior in 3D space.</p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Profile & Education -->
  <section id="profile" class="section alt-bg">
    <div class="container profile-two-col">
      <div class="profile-ed">
        <h2 class="section-title">Profile & Education</h2>
        <div class="edu-degree-block">
          <div class="edu-block">
            <div class="edu-logo">TAMU</div>
            <div>
              <span class="edu-title">Master of Science in Computer Science</span>
              <span class="edu-inst">Texas A&amp;M University</span>
              <span class="edu-dates">Aug 2024 – Jun 2026 (Expected), College Station, TX</span>
              <span class="edu-details">GPA: 4.0 / 4.0</span>
              <span class="edu-advisors">
                Advisors: <a href="https://czhang0528.github.io/" target="_blank">Prof. Cheng Zhang</a>, 
                <a href="https://engineering.tamu.edu/biomedical/profiles/avazmohammadi-reza.html" target="_blank">Dr. Reza Avazmohammadi</a>
              </span>
              <span class="edu-courses">Coursework: Vision Foundation Models, ML for 3D Visualization &amp; Graphics, Generative AI, Deep Reinforcement Learning, Research</span>
            </div>
          </div>
          <div class="edu-block">
            <div class="edu-logo">DTU</div>
            <div>
              <span class="edu-title">B.Tech in Information Technology</span>
              <span class="edu-inst">Delhi Technological University</span>
              <span class="edu-dates">Aug 2018 – May 2022, Delhi, India</span>
              <span class="edu-details">GPA: 8.6 / 10.0</span>
            </div>
          </div>
        </div>
      </div>
      <div class="profile-skills">
        <h2 class="section-title">Skills Overview</h2>
        <div class="skill-cat"><div class="cat-label">Domains</div>
          <div class="skills-list">
            <span class="tag">Embodied AI</span>
            <span class="tag">Egocentric Vision</span>
            <span class="tag">Human-Centric CV</span>
            <span class="tag">3D Scene Understanding</span>
            <span class="tag">Diffusion Models</span>
            <span class="tag">Medical Imaging</span>
            <span class="tag">3D Gaussian Splatting</span>
            <span class="tag">Multi-view Tracking</span>
          </div>
        </div>
        <div class="skill-cat"><div class="cat-label">Frameworks</div>
          <div class="skills-list">
            <span class="tag">PyTorch</span>
            <span class="tag">TensorFlow</span>
            <span class="tag">Keras</span>
            <span class="tag">HuggingFace</span>
            <span class="tag">Open3D</span>
            <span class="tag">PyVista</span>
            <span class="tag">Pandas</span>
            <span class="tag">Matplotlib</span>
            <span class="tag">Rerun.io</span>
            <span class="tag">Viser</span>
          </div>
        </div>
        <div class="skill-cat"><div class="cat-label">Programming</div>
          <div class="skills-list">
            <span class="tag">Python</span>
            <span class="tag">C++</span>
            <span class="tag">Rust</span>
            <span class="tag">JavaScript</span>
            <span class="tag">Matlab</span>
            <span class="tag">Ruby</span>
            <span class="tag">SQL</span>
          </div>
        </div>
        <div class="skill-cat"><div class="cat-label">Cloud/MLOps</div>
          <div class="skills-list">
            <span class="tag">AWS</span>
            <span class="tag">GCP</span>
            <span class="tag">Azure</span>
            <span class="tag">Docker</span>
            <span class="tag">Git</span>
          </div>
        </div>
        <div class="skill-cat"><div class="cat-label">Vision/NLP</div>
          <div class="skills-list">
            <span class="tag">OpenCV</span>
            <span class="tag">CNN</span>
            <span class="tag">RNN</span>
            <span class="tag">LLAMA-2</span>
            <span class="tag">Alpaca</span>
            <span class="tag">BERT</span>
            <span class="tag">RoBERTa</span>
            <span class="tag">Transformers</span>
          </div>
        </div>
        <div class="skill-cat"><div class="cat-label">Other</div>
          <div class="skills-list">
            <span class="tag">Retriever Augmented Generation</span>
            <span class="tag">3D Gaussian Splatting</span>
            <span class="tag">NeRF</span>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Professional Experience -->
  <section id="experience" class="section">
    <div class="container">
      <h2 class="section-title">Experience</h2>
      <div class="exp-columns">
        <!-- Each experience entry is a card, with good spacing and clear responsibility breakdown -->
        <div class="exp-card">
          <div class="exp-head-row">
            <div>
              <h3>Research Intern, AI4Arch</h3>
              <div class="exp-metadata">
                <span>June 2025 – August 2025 | College Station, TX</span>
              </div>
            </div>
            <div class="exp-meta-details">
              <div><b>Advisor:</b> Dr. Cheng Zhang &bull; Dr. Roxana Jafari</div>
              <div><b>Technologies:</b> PyTorch, YOLOv11, ONNX, SMPL</div>
            </div>
          </div>
          <ul class="exp-details">
            <li>Developed multi-view detection (YOLOv11) & tracking algorithm based on generative feature template for real-time people tracking & re-identification in Intensive Healthcare Units.</li>
            <li>Constructed the observed 3D Scene with objects using multi-view input for representing humans in 3D (SMPL) to flag harmful behaviour according to health codes.</li>
          </ul>
        </div>

        <div class="exp-card">
          <div class="exp-head-row">
            <div>
              <h3>Student Assistant, C2B Lab</h3>
              <div class="exp-metadata">
                <span>Sep 2024 – Present | College Station, TX</span>
              </div>
            </div>
            <div class="exp-meta-details">
              <div><b>Advisor:</b> Dr. Reza Avazmohammadi</div>
              <div><b>Technologies:</b> PyTorch, Matlab, Python, Viser</div>
            </div>
          </div>
          <ul class="exp-details">
            <li>Currently working on 4D motion tracking of heart by mapping 2D-based motion to 3D using motion interpolation.</li>
            <li>Devised novel semi-supervised diffusion based image registration approach for achieving 2D motion tracking of Rat’s Heart.</li>
            <li>Developed geometry-aware (2D slice prior) diffusion based 3D reconstruction model for precise mesh generation of Rat’s Heart.</li>
          </ul>
        </div>

        <div class="exp-card">
          <div class="exp-head-row">
            <div>
              <h3>Machine Learning Engineer-2, AfterShoot</h3>
              <div class="exp-metadata">
                <span>Nov 2023 – Jul 2024 | Delhi, India</span>
              </div>
            </div>
            <div class="exp-meta-details">
              <div><b>Technologies:</b> Python, C++, Rust, RunPod, GCP, Azure, PyTorch, TensorFlow</div>
            </div>
          </div>
          <ul class="exp-details">
            <li>Spearheaded development of AI portrait enhancement and retouching, delivering features (teeth correction, whitening, skin retouching). Product reduced Photoshop time from 10s of hours to &lt;2-3 hours for ~1000 photos.</li>
            <li>Engineered/deployed U-Net based generative model allowing generative teeth correction in portraits.</li>
            <li>Accelerated photo editing workflow by 40% by designing lightweight models automating HSL filters in Lightroom Classic.</li>
          </ul>
        </div>

        <div class="exp-card">
          <div class="exp-head-row">
            <div>
              <h3>Machine Learning Engineer, Savart</h3>
              <div class="exp-metadata">
                <span>Jan 2023 – Oct 2023 | Hyderabad, India</span>
              </div>
            </div>
            <div class="exp-meta-details">
              <div><b>Technologies:</b> Python, C++, AWS, GCP, Azure, PyTorch</div>
            </div>
          </div>
          <ul class="exp-details">
            <li>Fine-tuned LLAMA-2 and Alpaca models on financial annual reports that boosted qualitative company profiling used in equity market analysis; boosted the efficiency of equity market research from weeks to days.</li>
            <li>Engineered dynamic OCR pipeline & automated information extraction; processed 50K+ documents for corpus creation.</li>
            <li>Enhanced QA accuracy by 35% through strategic optimization of reader models (RoBERTa, BART, XLM) on new datasets.</li>
          </ul>
        </div>

        <div class="exp-card">
          <div class="exp-head-row">
            <div>
              <h3>Deep Learning Intern, HyperVerge Ltd</h3>
              <div class="exp-metadata">
                <span>Jul 2022 – Dec 2022 | Bangalore, India</span>
              </div>
            </div>
            <div class="exp-meta-details">
              <div><b>Supervisor:</b> <a href="https://www.linkedin.com/in/hariprasad-p-s-162b0778/" target="_blank">Hariprasad P S</a></div>
            </div>
          </div>
          <ul class="exp-details">
            <li>Spearheaded R&D for industry-leading ID tampering detection system that processes 15M+ monthly requests worldwide, serving 100+ clients.</li>
            <li>Developed tampering detection system achieving unprecedented 98% catch rate with &lt;1% false positive rate.</li>
            <li>Proposed and demonstrated the ATAC-Net anomaly detection architecture, leveraging memory-based semi-supervised learning (MemSeg, DeviationNet, WS-DAN); selected as best 5% and spotlight at ICIP 2024.</li>
          </ul>
        </div>
      </div>
    </div>
  </section>

  <!-- Research Projects -->
  <section id="research" class="section alt-bg">
    <div class="container">
      <h2 class="section-title">Research</h2>
      <div class="vertical-list">
        <div class="proj-entry">
          <div class="proj-title">Egocentric view driven Fine-Grained Object Interaction Trajectory &amp; Affordance Prediction
            <span class="proj-links">
              <a href="https://drive.google.com/file/d/1NRk8QdZimCRbG5Muhsr0HFvoEMv-Hkx1/view" target="_blank" class="proj-link-btn">View Project</a>
            </span>
          </div>
          <div class="meta">May 2025 – Present | Advisor: <a href="https://czhang0528.github.io/" target="_blank">Prof. Cheng Zhang</a></div>
          <div class="desc">Developing egocentric view driven end-to-end framework for predicting temporal future location prediction in 3D voxel scene representation along with precise & fine-grained affordance trajectory to interact with the object.</div>
        </div>
        <div class="proj-entry">
          <div class="proj-title">HG-SCRUB (Human-Gaussian Scene Representation with Unified Baking)
            <span class="proj-links">
              <a href="https://hg-scrub.github.io/HG-SCRUB/" target="_blank" class="proj-link-btn">Website</a>
            </span>
          </div>
          <div class="meta">Jan 2025 – May 2025</div>
          <div class="desc">Developed framework for human and scene decomposition in separate representations given sparse image frames from video; learned material and physical components (Normals, Albedo, Roughness & Metallic) and explicit normal learning with depth derivation and baking for relightable human gaussians.</div>
        </div>
        <div class="proj-entry">
          <div class="proj-title">Free-Generation (Training-Free Video Diffusion Control)
            <span class="proj-links">
              <a href="https://drive.google.com/file/d/1NRk8QdZimCRbG5Muhsr0HFvoEMv-Hkx1/view" target="_blank" class="proj-link-btn">Project PDF</a>
            </span>
          </div>
          <div class="meta">Aug 2024 – Dec 2024 | Advisor: <a href="https://czhang0528.github.io/" target="_blank">Prof. Cheng Zhang</a></div>
          <div class="desc">Conducted empirical research on Training-Free Trajectory Control Methods in Video Diffusion Models, including domain-shift identification in attention block statistics and formulation of statistical post-mask normalization for enhanced trajectory control.</div>
        </div>
      </div>
    </div>
  </section>

  <!-- Publications -->
  <section id="publications" class="section">
    <div class="container">
      <h2 class="section-title">Publications</h2>
      <div class="vertical-list">
        <div class="pub-entry">
          <div class="pub-title"><b>ATAC-Net: Zoomed view works better for Anomaly Detection</b>
            <a href="https://ieeexplore.ieee.org/abstract/document/10647702" class="pub-link" target="_blank">Paper</a>
            <a href="#" class="pub-link" target="_blank">Code</a>
          </div>
          <div class="meta">ICIP 2024 | Shaurya Gupta, <b>Neil Gautam</b>, Anurag Malyala</div>
          <div class="desc">Memory-based semi-supervised architecture (ATAC-Net) achieving 98% catch rate &lt;1% false positive. ICIP 2024 spotlight (top 5%).</div>
        </div>
        <div class="pub-entry">
          <div class="pub-title"><b>Obscenity Detection in Videos through Sequential ConvNet Pipeline Classifier</b>
            <a href="https://ieeexplore.ieee.org/abstract/document/9733936" class="pub-link" target="_blank">Paper</a>
          </div>
          <div class="meta">IEEE TCDS | <b>Neil Gautam</b>, Dr. Dinesh Kumar Vishwakarma</div>
          <div class="desc">ConvNet pipeline for video content moderation using spatial-temporal features for real-time analysis.</div>
        </div>
        <div class="pub-entry">
          <div class="pub-title"><b>Ensemble Learning Using Vision Transformer and CNN for Person ReID</b>
            <a href="https://ieeexplore.ieee.org/abstract/document/9753761" class="pub-link" target="_blank">Paper</a>
          </div>
          <div class="meta">IEEE ICCMC | Gupta, <b>Neil Gautam</b>, Dr. Vishwakarma</div>
          <div class="desc">Ensemble with Vision Transformer &amp; CNNs for improved person re-ID across challenging datasets.</div>
        </div>
      </div>
    </div>
  </section>

  <!-- Contact & Links -->
  <section id="contact" class="section alt-bg">
    <div class="container">
      <h2 class="section-title">Contact</h2>
      <div class="contact-grid">
        <div>
          <span class="c-label">Email:</span>
          <a href="mailto:neilgautam.24@tamu.edu"><i class="bi bi-envelope-at"></i> neilgautam.24@tamu.edu</a>
        </div>
        <div>
          <span class="c-label">Phone:</span>
          <a href="tel:+19797213148"><i class="bi bi-telephone"></i> +1 (979) 721-3148</a>
        </div>
        <div>
          <span class="c-label">Location:</span> College Station, TX
        </div>
        <div>
          <span class="c-label">LinkedIn:</span>
          <a href="https://www.linkedin.com/in/neil-gautam-a928971a5/" target="_blank"><i class="bi bi-linkedin"></i></a>
          <span class="c-label">GitHub:</span>
          <a href="https://github.com/neilgautam24-tamu" target="_blank"><i class="bi bi-github"></i></a>
          <span class="c-label">Google Scholar:</span>
          <a href="https://scholar.google.com/citations?user=CUISVw8AAAAJ&hl=en" target="_blank"><i class="bi bi-google"></i></a>
        </div>
      </div>
      <div class="contact-grid mentors">
        <div><span class="c-label">Mentors / Collaborators:</span>
          <a href="https://czhang0528.github.io/" target="_blank">Cheng Zhang</a> |
          <a href="https://engineering.tamu.edu/biomedical/profiles/avazmohammadi-reza.html" target="_blank">Reza Avazmohammadi</a> |
          <a href="https://www.linkedin.com/in/hariprasad-p-s-162b0778/" target="_blank">Hariprasad P S</a> |
          <a href="https://www.linkedin.com/in/nikhil-bartwal-b07b501a3/" target="_blank">Nikhil Bartwal</a> |
          <a href="https://www.linkedin.com/in/suhruth-eedara-93858412b/" target="_blank">Suhruth Eedara</a>
        </div>
      </div>
    </div>
  </section>
</main>
</body>
</html>
